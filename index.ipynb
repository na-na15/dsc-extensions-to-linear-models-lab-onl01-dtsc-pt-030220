{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline boston housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Boston housing dataset \n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "boston = load_boston()\n",
    "\n",
    "y = pd.DataFrame(boston.target, columns=['target'])\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "X_scaled = scale(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "all_data = pd.concat([y, X_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934925"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression = LinearRegression()\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, X_scaled, y, scoring='r2', cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76341744 0.64681426 0.79214772 0.65075105 0.73525883]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(regression, X_scaled, y, scoring='r2', cv=crossvalidation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934925"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(combinations)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions: [('RM', 'LSTAT', 0.783), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.77), ('RM', 'PTRATIO', 0.764), ('INDUS', 'RM', 0.757), ('NOX', 'RM', 0.746), ('RM', 'AGE', 0.742)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "combinations = list(combinations(boston.feature_names, 2))\n",
    "\n",
    "interactions = []\n",
    "data = X_scaled.copy()\n",
    "for comb in combinations:\n",
    "    data['interaction'] = data[comb[0]] * data[comb[1]]\n",
    "    \n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=crossvalidation))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score, 3)))\n",
    "            \n",
    "print('Top 7 interactions: %s' %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_interactions\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_inter = X_scaled.copy()\n",
    "ls_interactions = sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7]\n",
    "for inter in ls_interactions:\n",
    "    df_inter[inter[0] + '_' + inter[1]] = X[inter[0]] * X[inter[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('RM', 4, 0.8), ('RM', 2, 0.782), ('LSTAT', 4, 0.782), ('RM', 3, 0.781), ('LSTAT', 3, 0.774), ('LSTAT', 2, 0.772), ('DIS', 3, 0.737), ('DIS', 2, 0.732), ('DIS', 4, 0.731), ('TAX', 4, 0.724)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = []\n",
    "for col in X.columns:\n",
    "    for degree in [2, 3, 4]:\n",
    "        data = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X_transformed = poly.fit_transform(X[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X_transformed)], axis=1)\n",
    "        score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=crossvalidation))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score, 3)))\n",
    "print('Top 10 polynomials: %s' %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ZN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ZN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ZN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>INDUS</td>\n",
       "      <td>2</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INDUS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1      2\n",
       "0     ZN  2  0.720\n",
       "1     ZN  3  0.723\n",
       "2     ZN  4  0.720\n",
       "3  INDUS  2  0.723\n",
       "4  INDUS  3  0.723"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynom.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ZN         0.723\n",
       "INDUS      0.723\n",
       "NOX        0.721\n",
       "RM         0.800\n",
       "AGE        0.722\n",
       "DIS        0.737\n",
       "RAD        0.720\n",
       "TAX        0.724\n",
       "PTRATIO    0.721\n",
       "B          0.720\n",
       "LSTAT      0.782\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "polynom = pd.DataFrame(polynomials)\n",
    "polynom.groupby([0], sort=False)[2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in ['RM', 'LSTAT']:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X_transformed = poly.fit_transform(X[[col]])\n",
    "    colnames= [col, col + '_' + '2',  col + '_' + '3', col + '_' + '4']\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1), pd.DataFrame(X_transformed, columns=colnames)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.537350</td>\n",
       "      <td>428.6900</td>\n",
       "      <td>6.575</td>\n",
       "      <td>43.230625</td>\n",
       "      <td>284.241359</td>\n",
       "      <td>1868.886938</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.8004</td>\n",
       "      <td>123.505992</td>\n",
       "      <td>615.059840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>3.011449</td>\n",
       "      <td>506.6169</td>\n",
       "      <td>6.421</td>\n",
       "      <td>41.229241</td>\n",
       "      <td>264.732956</td>\n",
       "      <td>1699.850313</td>\n",
       "      <td>9.14</td>\n",
       "      <td>83.5396</td>\n",
       "      <td>763.551944</td>\n",
       "      <td>6978.864768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>3.369765</td>\n",
       "      <td>439.0035</td>\n",
       "      <td>7.185</td>\n",
       "      <td>51.624225</td>\n",
       "      <td>370.920057</td>\n",
       "      <td>2665.060607</td>\n",
       "      <td>4.03</td>\n",
       "      <td>16.2409</td>\n",
       "      <td>65.450827</td>\n",
       "      <td>263.766833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>3.205084</td>\n",
       "      <td>320.5084</td>\n",
       "      <td>6.998</td>\n",
       "      <td>48.972004</td>\n",
       "      <td>342.706084</td>\n",
       "      <td>2398.257176</td>\n",
       "      <td>2.94</td>\n",
       "      <td>8.6436</td>\n",
       "      <td>25.412184</td>\n",
       "      <td>74.711821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>3.273326</td>\n",
       "      <td>387.3674</td>\n",
       "      <td>7.147</td>\n",
       "      <td>51.079609</td>\n",
       "      <td>365.065966</td>\n",
       "      <td>2609.126456</td>\n",
       "      <td>5.33</td>\n",
       "      <td>28.4089</td>\n",
       "      <td>151.419437</td>\n",
       "      <td>807.065599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO  ...    NOX_RM    RM_AGE     RM       RM_2  \\\n",
       "0 -0.982843 -0.666608 -1.459000  ...  3.537350  428.6900  6.575  43.230625   \n",
       "1 -0.867883 -0.987329 -0.303094  ...  3.011449  506.6169  6.421  41.229241   \n",
       "2 -0.867883 -0.987329 -0.303094  ...  3.369765  439.0035  7.185  51.624225   \n",
       "3 -0.752922 -1.106115  0.113032  ...  3.205084  320.5084  6.998  48.972004   \n",
       "4 -0.752922 -1.106115  0.113032  ...  3.273326  387.3674  7.147  51.079609   \n",
       "\n",
       "         RM_3         RM_4  LSTAT  LSTAT_2     LSTAT_3      LSTAT_4  \n",
       "0  284.241359  1868.886938   4.98  24.8004  123.505992   615.059840  \n",
       "1  264.732956  1699.850313   9.14  83.5396  763.551944  6978.864768  \n",
       "2  370.920057  2665.060607   4.03  16.2409   65.450827   263.766833  \n",
       "3  342.706084  2398.257176   2.94   8.6436   25.412184    74.711821  \n",
       "4  365.065966  2609.126456   5.33  28.4089  151.419437   807.065599  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061549447222252"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "full_model = np.mean(cross_val_score(regression, df_inter, y, scoring='r2', cv=crossvalidation))\n",
    "full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.01303456e-01, 2.97196903e-01, 2.52318294e-01, 2.30678322e-01,\n",
       "       1.11698466e-01, 4.66139878e-02, 4.36979765e-02, 3.89721826e-02,\n",
       "       3.01076795e-02, 2.37881877e-02, 2.04705440e-02, 1.66913229e-02,\n",
       "       1.63486573e-02, 8.63040257e-03, 8.37243178e-03, 8.13617131e-03,\n",
       "       5.49645033e-03, 5.42138946e-03, 4.56081335e-03, 3.31590064e-03,\n",
       "       3.19358180e-03, 2.76616741e-03, 2.69473833e-03, 1.38219693e-03,\n",
       "       1.32984060e-03, 1.20711785e-03, 1.09332345e-03, 9.91464615e-04,\n",
       "       9.46346981e-04, 5.95940352e-04, 5.23084607e-04, 2.94438801e-04,\n",
       "       2.93805810e-04, 2.90173660e-04, 2.21212501e-04, 1.52648764e-04,\n",
       "       1.46110060e-04, 1.21953108e-04, 1.16958625e-04, 9.38175520e-05,\n",
       "       8.52234840e-05, 6.64493092e-05, 6.15428863e-05, 4.23162697e-05,\n",
       "       2.15397409e-05, 9.16185244e-06, 8.94632034e-06, 8.83188370e-06,\n",
       "       8.67308792e-06, 5.53472968e-06, 5.13567635e-06, 4.25391464e-06,\n",
       "       4.04906267e-06, 3.83415497e-06, 3.76172355e-06, 3.62046297e-06,\n",
       "       1.04081679e-06, 6.22302178e-07, 3.75536340e-08])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aic.alphas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_aic_\n",
    "len(model_aic.criterion_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare R-squared and MSE using train-test split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7168057552393374\n",
      "Test r^2: 0.7789410172622855\n",
      "Training MSE: 22.477983821877896\n",
      "Test MSE: 21.89776539604951\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=1)\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Test r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8155720603121366\n",
      "Test r^2: 0.8648860563031304\n",
      "Training MSE: 14.638603436696359\n",
      "Test MSE: 13.384181018871207\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y, random_state=1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha= model_aic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.807489057780076\n",
      "Test r^2: 0.8775992537339209\n",
      "Training MSE: 15.280175797396733\n",
      "Test MSE: 12.124831087348998\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha= model_bic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))# Code for lasso with alpha from BIC\n",
    "lasso = None\n",
    "\n",
    "\n",
    "# Print R2 and MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
